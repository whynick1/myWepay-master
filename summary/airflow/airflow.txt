Summary

1. as we have realtime system, why batch system is needed to beat the CAP theorem
	ref: http://nathanmarz.com/blog/how-to-beat-the-cap-theorem.html


2. Python globals() method return dict of current globals symbol table
	# Inject the properties into the __dict__ for this module. This will allow
	# airflow to pick up the DAGs.
	globals().update(dag_dict)


3. decorator in airflow 
	Function decorator that Looks for an argument named "default_args", and fills the unspecified arguments from it
    https://github.com/apache/incubator-airflow/blob/master/airflow/utils/decorators.py#L32-L88


4. use md5hash to distribute runtimes for jobs
    # value between 0 and 160 which is not intended to be perfectly uniform
    md5 = hashlib.md5()
    md5.update(str((cluster, db, table)).encode('utf8'))
	schedule_interval='{:d} */2 * * *'.format(int(md5.hexdigest(), 16) % 60)
	ref: https://en.wikipedia.org/wiki/Cron


5. airflow command
	ref: https://airflow.apache.org/cli.html


6. setup py3 env for airflow
	only use python 3.6 for venv3 with help from pyenv
	https://stackoverflow.com/a/32672975


7. try to delete apache_airflow.egg-info if exception throw 
	pkg_resources.ResolutionError: Script 'scripts/airflow' not found in metadata 
	at '/Users/hongyiw/dev/airflow/apache_airflow.egg-info'


8. error open airflow UI while swtich between PY2 & PY3
	solve by clear brower cookie, as PY2 and PY3 code store in cookie are different


9. jinja templating is not rendered until execution
	ref: http://jinja.pocoo.org/docs/2.10/api/


10. how to get keyfile google cloud connection
	1) airflow will use `gcloud auth` user to connnect, if no key file is defined

	2) create keyfile.json from 'correct' service account under 'correct' project
		ref: https://console.cloud.google.com/iam-admin/serviceaccounts/project?project=mythic-crane-708

	3) how to know which service account to use
		select 'role' from menu, will see the 'right' service account after expend role
		ref: https://console.cloud.google.com/iam-admin/iam?project=mythic-crane-708


11. backfill & catchup
	1) start_date vs execution_date
		start date decide first execution date, and next execution date is decicded base on interval

	2) during backfill or catchup == true, catch up will start from first missing run since first execution date (would not change even start_date updated)

	3) catchup could be set either dag level, or configuration file level

	4) once catchup is turned on, all (limit to max_active_run) missing run will be scheduled in parallel and run in sequence


12. how elt partion load works
	1) to load big table, for each dag run (execution date), we only load rows within timestamp range (based on 'modify_time'); thus, we are expected to use catchup

	2) usually, we will do an incremental load every 15 minutes, and daily load that overwrites the entire dayâ€™s worth of data. (by setting "write_disposition = 'WRITE_APPEND'/'WRITE_TRUNCATE' in GCS_TO_BQ_OPERATOR)

	3) 15 m load will look back for 15m, actually load rows in 30m, thus lead to need for decuplication


13. how corrupt dag works
	1) according to "12", rows with "modify_time == null" will never be load until "modify_time is ready" (out of partition load range), this bring out the use of corrupt dag

	2) this is usally okay, but there is such case that people want to see "corrupt rows" in BQ

	3) corrupt dag will instead keep loading "corrupt rows" to a seperate "corrput DB table" by its own frequnency

	4) then, people query view can see both "good" and "corrupt" tuples, because views created through el.py are combination of "original BQ table" & "corrput DB table"


14. row count check mismatch potential causes
	1) inconsistency in mysql

	2) deletions in mysql

	3) de-dupe logic is wrong


15. airflow-dag repo structure (access control)
	1) elt: all elt pipeline from mysql to micro_bus
		https://elt-airflow.corp.wepay-inc.com

	2) dev: (an exception) has access to read micro-bus GCS & BQ, but can't write data to it (production)
		https://dev-airflow.corp.wepay-inc.com

	3) atomic_sled: house internal staging data
		https://tst-airflow-di.devops.wepay-inc.com

	4) silver_castle: house external staging data
		https://stg-airflow-di.devops.wepay-inc.com

	5) mythic_crane: house POC data
		https://poc-airflow-di.devops.wepay-inc.com

	6) platinum_fortress: currently only dbz pipeline
		https://prd-npci-airflow-di.wepay-inc.com

	7) mythic-crane => liquid-champion (poc)
	   atomic-sled => exalted-entry (tst)
	   silver-castle => macro-gadget (stg)
	   platinum-fortress => micro-bus (prd)

	8) a user want to access gcs need to request join a group that has the access (directly assign access to user not allowed)


16. airflow delayed load jobs
	After enabling SLA, we are experiencing SLA misses. Some learnings:
	1) The parallelism is honored
	
	2) SQLAlchemy pool size is not the current bottleneck
	
	3) The scheduler loop itself is pretty quick, ~30s, this is because the dag file processing is done asynchronously
	
	4) The el.py contains more than 100 dags and takes ~5m to process. For a dag with N tasks, it will take (N x processing time per iteration) to complete a dagrun. This makes it not possible for 15m load jobs to catch up once they fell behind.
	
	5) The max_thread config does not help with this situation because the parallelism is DAG file based, not dag based.
	
	6) The solution is to separate el.py into individual dag files, one file per dag


17. airflow oncall
	1) too much scheduled tasks
		check maximum pool size

	2) tasks status always null
		(1) airflow GCS logging is not properly configured
			in kibana: airflow.utils.log.gcs_task_handler.GCSTaskHandler gcs_write - Could not write logs to gs://atomic-sled-797-airflow-di-logs/db_monolith_wepay_users_partition_1d/<span class="highlight">db2gcs_wepay.users</span>/2011-08-24T04:00:00/1.log

		(2) email is not configured properly:
			ValueError: invalid literal for int() with base 10

		(3) cannot import xxx
			add dependency to CLASSPATH, or cherry-pick the new commit (hook/operator)

	3) monolith db view is generated automatically, for micro-service ones, have to do it manually
	
	4) for any new table added to elt-airflow, we need to create a Devops Jira ticket, to request for select access
		ref: https://jira.corp.wepay-inc.com/browse/DEVOPS-7831


18. airflow 10
	1) we added timezone support

	2) and datetime are changed to timestamp


19. when the first run start according to start_date?
	The Airflow scheduler triggers the task soon after the start_date + scheduler_interval is passed.

